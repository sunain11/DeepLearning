{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunain11/DeepLearning/blob/master/DeepLearning7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BO9D9vN8iVJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "60ecb781-8d5d-4957-a2a7-7f19b2a71a59"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM#, CuDNNLSTM\n",
        "\n",
        "\n",
        "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
        "\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_train[0].shape)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# IF you are running with a GPU, try out the CuDNNLSTM layer type instead (don't pass an activation, tanh is required)\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=3,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(28, 28)\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 413s 7ms/sample - loss: 0.6746 - acc: 0.7752 - val_loss: 0.1418 - val_acc: 0.9564\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 410s 7ms/sample - loss: 0.1574 - acc: 0.9567 - val_loss: 0.1030 - val_acc: 0.9693\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 425s 7ms/sample - loss: 0.1051 - acc: 0.9718 - val_loss: 0.0715 - val_acc: 0.9801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f29758f3dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}